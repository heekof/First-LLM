{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ce52b1-e1a1-4f6e-871f-6d59fa4f26fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start-of-sentence', 'object', 'that', 'has', 'a', 'no-return', 'boundary', 'for', 'other', 'uses', 'see', 'black', 'hole', '(disambiguation)', 'end-of-sentence', 'start-of-sentence', 'direct', 'radio', 'image', 'of', 'a', 'supermassive', 'black', 'hole', 'at', 'the', 'core', 'of', 'messier', '87', 'animated', 'simulation', 'of', 'a', 'schwarzschild', 'black', 'hole', 'with', 'a', 'galaxy', 'passing', 'behind', 'end-of-sentence', 'start-of-sentence', 'around', 'the', 'time', 'of', 'alignment', 'extreme', 'gravitational', 'lensing', 'of', 'the', 'galaxy', 'is', 'observed', 'end-of-sentence', 'start-of-sentence', 'a', 'black', 'hole', 'is', 'a', 'region', 'of', 'spacetime', 'where', 'gravity', 'is', 'so', 'strong', 'that', 'nothing', 'including', 'light', 'and', 'other', 'electromagnetic', 'waves', 'has', 'enough', 'energy', 'to', 'escape', 'it', 'end-of-sentence', 'start-of-sentence', 'einstein', 's', 'theory', 'of', 'general', 'relativity', 'predicts', 'that', 'a', 'sufficiently', 'compact', 'mass']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "import random\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "file_path = '/Users/jaafarbendriss/First-LLM/dataset/black_hole_wiki.txt'\n",
    "\n",
    "# Open the file and read its content\n",
    "with open(file_path, 'r') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "raw_text = file_content\n",
    "\n",
    "def add_start_end_sentence(text):\n",
    "    return \"start-of-sentence \" + text.replace(\".\",\" end-of-sentence start-of-sentence\")\n",
    "\n",
    "\n",
    "def remove_citations(text):\n",
    "    pattern = r\"\\[\\d+\\]\"\n",
    "    cleaned_text = re.sub(pattern, \"\", text)    \n",
    "    return cleaned_text\n",
    "\n",
    "def remove_spaces(text):\n",
    "    pattern = r\"\\s+\"\n",
    "    cleaned_text = re.sub(pattern, \" \", text)    \n",
    "    return cleaned_text\n",
    "\n",
    "def preprocess(text: str):\n",
    "    return remove_spaces(remove_citations(add_start_end_sentence(text).lower().replace(\" s \",\"\").replace(\"\\\\\",\"\").replace(\"'\",\" \").replace('\"',' ').replace(\",\",\" \").replace(\"\\ s\",\" \").replace(\"\\n\",\" \")))\n",
    "\n",
    "preprocessed_text = preprocess(raw_text)\n",
    "\n",
    "Counter(preprocessed_text.split(\" \")).most_common(20)\n",
    "\n",
    "preprocessed_text_array = preprocessed_text.split(\" \")\n",
    "\n",
    "\n",
    "print(preprocessed_text_array[0:100])\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "tokens = tokenizer(preprocessed_text)\n",
    "\n",
    "preprocessed_text = preprocessed_text.replace(\"end-of-sentence start-of-sentence\", \"end-of-sentence69696969start-of-sentence\")\n",
    "splited_data = preprocessed_text.split(\"69696969\")\n",
    "\n",
    "train_data =  [(i,sentence) for i, sentence in zip( range(0,len(splited_data)), splited_data  )]\n",
    "train_iter = iter(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b653746-6214-4009-9a0d-bad541481b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'start-of-sentence object that has a no-return boundary for other uses see black hole (disambiguation) end-of-sentence')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df63202c-3e25-4118-969e-4b545e05d36e",
   "metadata": {},
   "source": [
    "## Preparing training dataset using sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4dbc77-59e6-4d36-9a57-c51b447a2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence =  'start-of-sentence object that has a no-return boundary for other uses see black hole (disambiguation) end-of-sentence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f19f6c0-a825-406c-b329-985f57e60d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0645ed8-70b9-45d5-9d4e-12a28b0f912d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['start-of-sentence object that has a no-return boundary for other uses see black hole (disambiguation) end-of-sentence',\n",
       " 'start-of-sentence direct radio image of a supermassive black hole at the core of messier 87 animated simulation of a schwarzschild black hole with a galaxy passing behind end-of-sentence']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splited_data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c2db28-99c0-4569-9e19-102d90daf692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 37, 10, 66, 6, 0, 186, 16, 68, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "vocab(tokens[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "840ca675-54f9-48f1-b915-54e22bf0abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_map = vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d1e4407-b80a-42a5-bd7b-589576be6d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'start-of-sentence the presence of a black hole can be inferred through its interaction with other matter and with electromagnetic radiation such as visible light end-of-sentence'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splited_data[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49171cbb-4dd0-4b78-9a51-e4f5cd9e2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "for sentence in splited_data:\n",
    "    data=sentence.split()\n",
    "    for i in range(1,len(data)):\n",
    "        X=data[0:i]\n",
    "        y = data[i]\n",
    "        training_data.append((X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f718ebe-62c5-4dae-a6ac-9e51be13004b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11538"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00b9f1ca-3f95-4258-aeaa-c4f05a0fd6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['start-of-sentence', 'direct', 'radio', 'image', 'of', 'a', 'supermassive'],\n",
       "  'black')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[20:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92663eb6-c080-4904-8510-a23d37ec34b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second method\n",
    "\n",
    "training_data_cut = []\n",
    "\n",
    "for sentence in splited_data:\n",
    "    data=sentence.split()\n",
    "    for i in range(1,len(data)):\n",
    "        X=data[max([0,i-5]):i]\n",
    "        y = data[i]\n",
    "        training_data_cut.append((X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d06bf5fe-a942-4d7b-9e4e-1ef40e8ee3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['radio', 'image', 'of', 'a', 'supermassive'], 'black')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_cut[20:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5c122cd-298a-453e-8894-b1e2f7991b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_token = token_map\n",
    "\n",
    "def word_to_token_wrapper(word: str) -> int:\n",
    "    if word not in word_to_token:\n",
    "        return word_to_token[\"<unk>\"]\n",
    "    return word_to_token[word]\n",
    "\n",
    "def list_sentence_to_token(sentence_list)->int:\n",
    "    return [word_to_token_wrapper(word) for word in sentence_list]\n",
    "\n",
    "def sentence_to_token(sentence):\n",
    "    return [word_to_token_wrapper(word) for word in sentence.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4387afe-d8bc-4148-b468-15aa3b2ee7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_token(\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6c2a92a-8f76-469f-8f34-28b5a0470df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_token[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f290f3b2-10c5-404c-a0f4-e9614fc3c6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['start-of-sentence', 'object', 'that', 'has', 'a'], 'no-return')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_cut[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "244187ee-b1c8-4b44-83d7-dd8c518662c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_tokenized = [ (list_sentence_to_token(a),word_to_token_wrapper(b) ) for a,b in training_data_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2c6c21c-4854-4e29-b413-f390e3653532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([186, 2, 92, 138, 12], 115),\n",
       " ([2, 92, 138, 12, 115], 1),\n",
       " ([92, 138, 12, 115, 1], 26),\n",
       " ([138, 12, 115, 1, 26], 29),\n",
       " ([12, 115, 1, 26, 29], 3)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_tokenized[110:115]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d820d50d-7e6b-4ab1-8385-795a0694b913",
   "metadata": {},
   "source": [
    "## training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74579798-7a23-456b-8680-6921454d61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SentenceCompletionDataset(Dataset):\n",
    "    def __init__(self, data, word_to_index):\n",
    "        self.data = data\n",
    "        self.word_to_index = word_to_index\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_sequence, target_word = self.data[idx]\n",
    "        input_indices = [self.word_to_index[word] for word in input_sequence]\n",
    "        target_index = self.word_to_index[target_word]\n",
    "        return torch.tensor(input_indices, dtype=torch.long), torch.tensor(target_index, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e4bfb11-3185-4466-9c2a-3d1c7171b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming train_data is a list of sentences\n",
    "train_sentences, val_sentences = train_test_split(training_data_tokenized, test_size=0.3, random_state=42)\n",
    "\n",
    "# Now, apply the masking and preparation logic to both train_sentences and val_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9f8b5-2e16-4feb-9747-fa2f40f18a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38d86824-d260-49d7-8963-4dd9afd0cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens, target = self.data[idx]\n",
    "        return torch.tensor(tokens, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "# Assuming `data` is your list of mappings\n",
    "dataset = TokenDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3675f709-5751-4b03-9046-4ed8aedca1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    tokens, targets = zip(*batch)\n",
    "    # Pad the sequences to the maximum length in the batch\n",
    "    tokens_padded = pad_sequence([torch.tensor(seq) for seq in tokens], batch_first=True, padding_value=0)\n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "    return tokens_padded, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00a5f36f-3a23-456c-91e0-be7e2e70d5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8076"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb18544b-134f-458f-a51e-03ebb168c25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2147"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word_to_token)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42158537-22cc-402d-8401-3ffa811693d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,dropout_rate=0.5):\n",
    "        super(SimpleLM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Add dropout layer\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, tokens):\n",
    "        embedded = self.embedding(tokens)  # [batch_size, seq_len, embedding_dim]\n",
    "        # Aggregate embeddings, e.g., by averaging\n",
    "        aggregated = embedded.mean(dim=1)  # [batch_size, embedding_dim]\n",
    "        hidden = self.relu(self.linear1(aggregated))  # [batch_size, hidden_dim]\n",
    "        output = self.linear2(hidden)  # [batch_size, output_dim]\n",
    "        return output\n",
    "\n",
    "# Hyperparameters\n",
    "#vocab_size = 2145  # Adjust based on your dataset\n",
    "embedding_dim = 50\n",
    "hidden_dim = 20\n",
    "output_dim = vocab_size  # Same as vocab size for prediction\n",
    "\n",
    "model = SimpleLM(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e48738-f9ae-44fd-b506-5adc25eab787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25a63ff8-a177-479e-8eac-3173359c62a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8076"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "762211de-4b69-46c6-9491-35d0f19cc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d083c5d-019f-45bf-bd81-a4e42b1db816",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TokenDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57b5517e-15b1-4ae5-8305-e66a669d5298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/bv3z08h91lggkmhcp2n7yzh80000gn/T/ipykernel_74746/763346120.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokens_padded = pad_sequence([torch.tensor(seq) for seq in tokens], batch_first=True, padding_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.4738432998114295\n",
      "Epoch 11, Loss: 3.7057437417235706\n",
      "Epoch 21, Loss: 2.3452130593728313\n",
      "Epoch 31, Loss: 1.7310304481185752\n",
      "Epoch 41, Loss: 1.3395805589930792\n",
      "Epoch 51, Loss: 1.0698184460098394\n",
      "Epoch 61, Loss: 0.8778534088267064\n",
      "Epoch 71, Loss: 0.7375941460294156\n",
      "Epoch 81, Loss: 0.6320147079432621\n",
      "Epoch 91, Loss: 0.5492831248257513\n",
      "Epoch 101, Loss: 0.48809121044883114\n",
      "Epoch 111, Loss: 0.44342492915242393\n",
      "Epoch 121, Loss: 0.4098725147817182\n",
      "Epoch 131, Loss: 0.38513790079194016\n",
      "Epoch 141, Loss: 0.36309760622634996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nembedding_dim = 50\\nhidden_dim = 20\\ndropout = 0.5\\n0.3662537602579914\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 150  # Or whatever suits your dataset\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for tokens, target in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(tokens)\n",
    "        loss = criterion(output, target.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    if epoch %10 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}')\n",
    "\n",
    "# batch 5 => Epoch 141, Loss: 0.3472299749050117\n",
    "# batch 7 => Epoch 141, Loss: 0.3254897424296818\n",
    "\n",
    "# batch 5 and window 5 => Epoch 141, Loss: 0.2996615952255913\n",
    "\"\"\"\n",
    "embedding_dim = 80\n",
    "hidden_dim = 50\n",
    "0.26723970297246136\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "embedding_dim = 40\n",
    "hidden_dim = 20\n",
    "0.37902324068592874\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "embedding_dim = 50\n",
    "hidden_dim = 20\n",
    "dropout = 0.5\n",
    "0.3662537602579914\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d31d31d-342d-4730-90f5-0cacb57a9300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([4, 1, 186, 2, 92, 138, 12], 115),\n",
       " ([4, 1, 186, 2, 92, 138, 12, 115], 1),\n",
       " ([4, 1, 186, 2, 92, 138, 12, 115, 1], 26),\n",
       " ([4, 1, 186, 2, 92, 138, 12, 115, 1, 26], 29),\n",
       " ([4, 1, 186, 2, 92, 138, 12, 115, 1, 26, 29], 3)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[([4, 1, 186, 2, 92, 138, 12], 115),\n",
    " ([4, 1, 186, 2, 92, 138, 12, 115], 1),\n",
    " ([4, 1, 186, 2, 92, 138, 12, 115, 1], 26),\n",
    " ([4, 1, 186, 2, 92, 138, 12, 115, 1, 26], 29),\n",
    " ([4, 1, 186, 2, 92, 138, 12, 115, 1, 26, 29], 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4f7d5eb-e01d-48a3-adac-63729f150b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([2, 1, 110, 160, 36], 34),\n",
       " ([147, 6, 2052, 20, 766], 71),\n",
       " ([50, 1069, 190, 7, 1], 410),\n",
       " ([42, 70, 115, 794, 42], 98),\n",
       " ([1370, 300, 64, 57, 53], 3)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae3f27dd-d8d2-492e-809b-41ff97d8f5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = sentence_to_token(\"the black\")\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb477f87-e39e-41b7-bea2-3b8188c90d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_word = {token: word for word, token in word_to_token.items()}\n",
    "\n",
    "def token_to_sentence(tokens):\n",
    "    return \" \".join([token_to_word[t] for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "371788de-aa99-40f3-a1bf-fafcfaee1dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of the photon orbit which'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_sentence([2, 1, 110, 160, 36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a26bc6e-8d86-4539-8689-3a25bad736bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2,   1, 110, 160,  36]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [2, 1, 110, 160, 36]\n",
    "sequence_tensor = torch.tensor(sequence).unsqueeze(0) \n",
    "sequence_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2acdbf9e-ce24-45d5-bdfe-10897409594f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    output = model(sequence_tensor)\n",
    "    predicted_token_id = output.argmax(dim=1).item()  # Get the index of the max log-probability\n",
    "predicted_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86d5e762-3274-41d3-9afd-da2848e8e499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_word[predicted_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e10f12d1-11c7-463b-94af-9bd981e2cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK = 1\n",
    "\n",
    "def predict_missing_word(sentence=\"black hole is the biggest object in the\"):\n",
    "    last_K = \" \".join(sentence.split()[-5:])\n",
    "    #print(last_K)                  \n",
    "    sequence = sentence_to_token(last_K)\n",
    "    sequence_tensor = torch.tensor(sequence).unsqueeze(0)  # Add batch dimension\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        output = model(sequence_tensor)\n",
    "        predicted_token_id = output.argmax(dim=1).item()  # Get the index of the max log-probability\n",
    "        #_, top5_indices = torch.topk(output[0], TOPK)\n",
    "        #predicted_token_id = random.choice(top5_indices.tolist())\n",
    "\n",
    "    # Assuming you have a token_to_word dictionary\n",
    "    token_to_word = {token: word for word, token in word_to_token.items()}\n",
    "    predicted_word = token_to_word[predicted_token_id]\n",
    "    return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18f15e78-739b-47c5-81c5-17b24d7e3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_missing_token(tokens):\n",
    "               \n",
    "    sequence = tokens[-5:]\n",
    "    sequence_tensor = torch.tensor(sequence).unsqueeze(0)  # Add batch dimension\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        output = model(sequence_tensor)\n",
    "        predicted_token_id = output.argmax(dim=1).item()  # Get the index of the max log-probability\n",
    "        #_, top5_indices = torch.topk(output[0], TOPK)\n",
    "        #predicted_token_id = random.choice(top5_indices.tolist())\n",
    "\n",
    "    return predicted_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "723e166b-8b2c-4fef-804a-2314d57e3c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disk'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_missing_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ebe4526-c249-4ba4-bfec-7a25f26fdb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'start-of-sentence [ edit ] main <unk> hawking radiation smaller of in and in sagittarius cannot resolve slowed better large density rotating rotating'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word = \"start-of-sentence\"\n",
    "#next_word = \"einstein\"\n",
    "words = []\n",
    "sentence = next_word\n",
    "words.append(next_word)\n",
    "limit = 0\n",
    "while next_word != \"end-of-sentence\" and limit<20:\n",
    "    #print(\"input \",sentence)\n",
    "    next_word = predict_missing_word(sentence)\n",
    "    #print(\"output \",next_word)\n",
    "    words.append(next_word)\n",
    "    sentence = \" \".join(words)\n",
    "    limit += 1\n",
    "words.append(next_word)\n",
    "\n",
    "\" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4aa36-370f-4fb6-90f4-946391f1bfdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b74c871-8701-4916-8b8d-bc4a2b28257f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "203 3462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nembedding_dim = 80\\nhidden_dim = 50\\n259 3462\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for s in val_sentences:\n",
    "    #print(s)\n",
    "    predicted_token = predict_missing_token(s[0]) \n",
    "    #print(\"predicted token = \", predicted_token)\n",
    "    answer = predicted_token == s[1]\n",
    "\n",
    "    if answer:\n",
    "        correct += answer\n",
    "\n",
    "print()\n",
    "print(correct,len(val_sentences))\n",
    "\"\"\"\n",
    "embedding_dim = 80\n",
    "hidden_dim = 50\n",
    "259 3462\n",
    "\"\"\"\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd128c04-0712-4795-a2bc-1530b18713ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7114 8076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nembedding_dim = 80\\nhidden_dim = 50\\n7261 8076\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for s in train_sentences:\n",
    "    #print(s)\n",
    "    predicted_token = predict_missing_token(s[0]) \n",
    "    #print(\"predicted token = \", predicted_token)\n",
    "    answer = predicted_token == s[1]\n",
    "\n",
    "    if answer:\n",
    "        correct += answer\n",
    "\n",
    "print()\n",
    "print(correct,len(train_sentences))\n",
    "\"\"\"\n",
    "embedding_dim = 80\n",
    "hidden_dim = 50\n",
    "7261 8076\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9773e1-a921-45ec-891b-d1c73f2d41a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85264cc-4bba-490b-a392-fc4bd36dc4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d33713-bfaa-42a8-88ad-736d325fd2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf1a33-6dcb-48a7-8f9c-15cdcf0d435c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
