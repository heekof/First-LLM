{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_reports = pd.read_csv(\"dataset/reports_copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>INDICATION: , Chest pain.,TYPE OF TEST: , Aden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>CHIEF COMPLAINT: , Chest pain.,HISTORY OF PRES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , The patient is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , Mr. ABC is a 60-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>REASON FOR CONSULTATION:  ,Abnormal echocardio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2179 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               medical_specialty  \\\n",
       "0     Cardiovascular / Pulmonary   \n",
       "1     Cardiovascular / Pulmonary   \n",
       "2     Cardiovascular / Pulmonary   \n",
       "3     Cardiovascular / Pulmonary   \n",
       "4     Cardiovascular / Pulmonary   \n",
       "...                          ...   \n",
       "2174  Cardiovascular / Pulmonary   \n",
       "2175  Cardiovascular / Pulmonary   \n",
       "2176  Cardiovascular / Pulmonary   \n",
       "2177  Cardiovascular / Pulmonary   \n",
       "2178  Cardiovascular / Pulmonary   \n",
       "\n",
       "                                                 report  \n",
       "0     2-D M-MODE: , ,1.  Left atrial enlargement wit...  \n",
       "1     1.  The left ventricular cavity size and wall ...  \n",
       "2     2-D ECHOCARDIOGRAM,Multiple views of the heart...  \n",
       "3     DESCRIPTION:,1.  Normal cardiac chambers size....  \n",
       "4     2-D STUDY,1. Mild aortic stenosis, widely calc...  \n",
       "...                                                 ...  \n",
       "2174  INDICATION: , Chest pain.,TYPE OF TEST: , Aden...  \n",
       "2175  CHIEF COMPLAINT: , Chest pain.,HISTORY OF PRES...  \n",
       "2176  HISTORY OF PRESENT ILLNESS: , The patient is a...  \n",
       "2177  HISTORY OF PRESENT ILLNESS: , Mr. ABC is a 60-...  \n",
       "2178  REASON FOR CONSULTATION:  ,Abnormal echocardio...  \n",
       "\n",
       "[2179 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2179 entries, 0 to 2178\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   medical_specialty  2179 non-null   object\n",
      " 1   report             2179 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.2+ KB\n"
     ]
    }
   ],
   "source": [
    "medical_reports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_reports = medical_reports.dropna(subset=[\"report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medical_specialty\n",
       "Cardiovascular / Pulmonary    110\n",
       "Gastroenterology              110\n",
       "Neurology                     110\n",
       "Radiology                     110\n",
       "Surgery                       110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN SET \n",
    "\n",
    "grouped_data = medical_reports.groupby(\"medical_specialty\").sample(110, random_state=69)\n",
    "grouped_data\n",
    "\n",
    "# Validation\n",
    "\n",
    "# 110 total points, randomly sample 10 of those and the from 10 to 5 instances to test and validation set\n",
    "\n",
    "ten_percent = grouped_data.groupby(\"medical_specialty\").sample(10, random_state=42)\n",
    "\n",
    "test_data =  ten_percent.head()\n",
    "\n",
    "validation_data =  ten_percent.tail()\n",
    "# TEST SET for validation\n",
    "\n",
    "grouped_data[\"medical_specialty\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Left pleural effusio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PROCEDURE: , Direct current cardioversion.,REA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PROCEDURE:  ,Trigger thumb release.,PROCEDURE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PROCEDURE: , Colonoscopy.,INDICATIONS: , Hemat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Right hand Dupuytren...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    medical_specialty                                             report\n",
       "122           Surgery  PREOPERATIVE DIAGNOSIS:,  Left pleural effusio...\n",
       "903           Surgery  PROCEDURE: , Direct current cardioversion.,REA...\n",
       "66            Surgery  PROCEDURE:  ,Trigger thumb release.,PROCEDURE ...\n",
       "810           Surgery  PROCEDURE: , Colonoscopy.,INDICATIONS: , Hemat...\n",
       "710           Surgery  PREOPERATIVE DIAGNOSIS: , Right hand Dupuytren..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>DISCHARGE DIAGNOSES:,1.  Chest pain.  The pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>PROCEDURE PERFORMED: , Endotracheal intubation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>REASON FOR CONSULTATION:,  Cardiomyopathy and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>INDICATIONS:,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>INDICATIONS FOR PROCEDURE:, The patient has pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DIAGNOSES:,1.  Intrauterine pregn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DX:, Dermatochalasis, mechanical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DIAGNOSES: , Dysphagia and esopha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , A 10-1/2 week pregna...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               medical_specialty  \\\n",
       "2076  Cardiovascular / Pulmonary   \n",
       "2015  Cardiovascular / Pulmonary   \n",
       "2091  Cardiovascular / Pulmonary   \n",
       "2     Cardiovascular / Pulmonary   \n",
       "1860  Cardiovascular / Pulmonary   \n",
       "...                          ...   \n",
       "918                      Surgery   \n",
       "407                      Surgery   \n",
       "974                      Surgery   \n",
       "591                      Surgery   \n",
       "37                       Surgery   \n",
       "\n",
       "                                                 report  \n",
       "2076  DISCHARGE DIAGNOSES:,1.  Chest pain.  The pati...  \n",
       "2015  PROCEDURE PERFORMED: , Endotracheal intubation...  \n",
       "2091  REASON FOR CONSULTATION:,  Cardiomyopathy and ...  \n",
       "2     2-D ECHOCARDIOGRAM,Multiple views of the heart...  \n",
       "1860                                      INDICATIONS:,  \n",
       "...                                                 ...  \n",
       "918   INDICATIONS FOR PROCEDURE:, The patient has pr...  \n",
       "407   PREOPERATIVE DIAGNOSES:,1.  Intrauterine pregn...  \n",
       "974   PREOPERATIVE DX:, Dermatochalasis, mechanical ...  \n",
       "591   PREOPERATIVE DIAGNOSES: , Dysphagia and esopha...  \n",
       "37    PREOPERATIVE DIAGNOSIS: , A 10-1/2 week pregna...  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = grouped_data[~grouped_data.index.isin(ten_percent.index)]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPREOPERATIVE DIAGNOSIS: , Aqueductal stenosis.,POSTOPERATIVE DIAGNOSIS:,  Aqueductal stenosis.,\\nTITLE OF PROCEDURE:  ,Endoscopic third ventriculostomy.,ANESTHESIA: , General endotracheal tube anesthesia.,\\nDEVICES:,  Bactiseal ventricular catheter with an Aesculap burr hole port.,\\nSKIN PREPARATION:  ,ChloraPrep.,COMPLICATIONS: , None.,SPECIMENS: , CSF for routine studies.,\\nINDICATIONS FOR OPERATION:  ,Triventricular hydrocephalus most consistent with aqueductal stenosis.  \\n    The patient having a long history of some intermittent headaches, macrocephaly.,\\nOPERATIVE PROCEDURE: , After satisfactory general endotracheal tube anesthesia was administered, \\nthe patient was positioned on the operating table in supine position with the head neutral.  \\nThe right frontal area was shaven and then the head was prepped and draped in a standard routine manner.  \\nThe area of the proposed scalp incision was infiltrated with 0.25% Marcaine with 1:200,000 epinephrine.  \\nA curvilinear scalp incision was made extending from just posterior to bregma curving up in the midline and then going off to the right anterior to the coronal suture.  \\nTwo Weitlaner were used to hold the scalp open.  A burr hole was made just anterior to the coronal suture and then the dura was opened in a cruciate manner and the pia was coagulated.\\nNeuropen was introduced directly through the parenchyma into the ventricular system, which was quite large and dilated.  \\nCSF was collected for routine studies.  We saw the total absence of __________  consistent with the congenital form of aqueductal stenosis and a markedly thinned down floor of the \\nthird ventricle.  I could bend the ventricular catheter and look back and see the aqueduct, which was quite stenotic with a little bit of chorioplexus near its opening.  \\nThe NeuroPEN was then introduced through the midline of the floor of the third ventricle anterior to the mamillary bodies in front of the basilar artery and then was gently enlarged \\nusing NeuroPEN __________  various motions.  We went through the membrane of Liliequist.  We could see the basilar artery and the clivus, and there was no significant bleeding from the edges.  \\nThe Bactiseal catheter was then left to 7 cm of length because of her macrocephaly and secured to a burr hole port with a 2-0 Ethibond suture.  \\nThe wound was irrigated out with bacitracin and closed using 3-0 Vicryl \\nfor the deep layer and a Monocryl suture for the scalp followed by Mastisol and Steri-Strips.  The patient tolerated the procedure well.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PREOPERATIVE DIAGNOSIS: , Aqueductal stenosis.,POSTOPERATIVE DIAGNOSIS:,  Aqueductal stenosis.,\n",
    "TITLE OF PROCEDURE:  ,Endoscopic third ventriculostomy.,ANESTHESIA: , General endotracheal tube anesthesia.,\n",
    "DEVICES:,  Bactiseal ventricular catheter with an Aesculap burr hole port.,\n",
    "SKIN PREPARATION:  ,ChloraPrep.,COMPLICATIONS: , None.,SPECIMENS: , CSF for routine studies.,\n",
    "INDICATIONS FOR OPERATION:  ,Triventricular hydrocephalus most consistent with aqueductal stenosis.  \n",
    "    The patient having a long history of some intermittent headaches, macrocephaly.,\n",
    "OPERATIVE PROCEDURE: , After satisfactory general endotracheal tube anesthesia was administered, \n",
    "the patient was positioned on the operating table in supine position with the head neutral.  \n",
    "The right frontal area was shaven and then the head was prepped and draped in a standard routine manner.  \n",
    "The area of the proposed scalp incision was infiltrated with 0.25% Marcaine with 1:200,000 epinephrine.  \n",
    "A curvilinear scalp incision was made extending from just posterior to bregma curving up in the midline and then going off to the right anterior to the coronal suture.  \n",
    "Two Weitlaner were used to hold the scalp open.  A burr hole was made just anterior to the coronal suture and then the dura was opened in a cruciate manner and the pia was coagulated.\n",
    "Neuropen was introduced directly through the parenchyma into the ventricular system, which was quite large and dilated.  \n",
    "CSF was collected for routine studies.  We saw the total absence of __________  consistent with the congenital form of aqueductal stenosis and a markedly thinned down floor of the \n",
    "third ventricle.  I could bend the ventricular catheter and look back and see the aqueduct, which was quite stenotic with a little bit of chorioplexus near its opening.  \n",
    "The NeuroPEN was then introduced through the midline of the floor of the third ventricle anterior to the mamillary bodies in front of the basilar artery and then was gently enlarged \n",
    "using NeuroPEN __________  various motions.  We went through the membrane of Liliequist.  We could see the basilar artery and the clivus, and there was no significant bleeding from the edges.  \n",
    "The Bactiseal catheter was then left to 7 cm of length because of her macrocephaly and secured to a burr hole port with a 2-0 Ethibond suture.  \n",
    "The wound was irrigated out with bacitracin and closed using 3-0 Vicryl \n",
    "for the deep layer and a Monocryl suture for the scalp followed by Mastisol and Steri-Strips.  The patient tolerated the procedure well.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting asked by openai\n",
    "\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cardiovascular / Pulmonary', 'Gastroenterology', 'Neurology',\n",
       "       'Radiology', 'Surgery'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"medical_specialty\"].unique()\n",
    "# We would like to classify the report into one medical specialty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"Given the medical report classify it into one of these medical categories : [Cardiovascular / Pulmonary, Gastroenterology, Neurology,Radiology, Surgery]\"\n",
    "\n",
    "sample_prompts = {\"messages\": [{'role':'system', 'content':system_prompt},{'role':'user', 'content':train['report'].iloc[0]},{'role':'assistant','content':train['medical_specialty'].iloc[0]}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'Given the medical report classify it into one of these medical categories : [Cardiovascular / Pulmonary, Gastroenterology, Neurology,Radiology, Surgery]'},\n",
       "  {'role': 'user',\n",
       "   'content': \"DISCHARGE DIAGNOSES:,1.  Chest pain.  The patient ruled out for myocardial infarction on serial troponins.  Result of nuclear stress test is pending.,2.  Elevated liver enzymes, etiology uncertain for an outpatient followup.,3.  Acid reflux disease.,TEST DONE: , Nuclear stress test, results of which are pending.,HOSPITAL COURSE: , This 32-year-old with family history of premature coronary artery disease came in for evaluation of recurrent chest pain, O2 saturation at 94% with both atypical and typical features of ischemia.  The patient ruled out for myocardial infarction with serial troponins.  Nuclear stress test has been done, results of which are pending.  The patient is stable to be discharged pending the results of nuclear stress test and cardiologist's recommendations.  He will follow up with cardiologist, Dr. X, in two weeks and with his primary physician in two to four weeks.  Discharge medications will depend on results of nuclear stress test.\"},\n",
       "  {'role': 'assistant', 'content': 'Cardiovascular / Pulmonary'}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'Given the medical report classify it into one of these medical categories : [Cardiovascular / Pulmonary, Gastroenterology, Neurology,Radiology, Surgery]'},\n",
       "  {'role': 'user',\n",
       "   'content': \"REASON FOR CONSULT: , I was asked to see this patient with metastatic non-small-cell lung cancer, on hospice with inferior ST-elevation MI.,HISTORY OF PRESENT ILLNESS: , The patient from prior strokes has expressive aphasia, is not able to express herself in a clear meaningful fashion.  Her daughter who accompanies her is very attentive whom I had met previously during drainage of a malignant hemorrhagic pericardial effusion last month.  The patient has been feeling well for the last several weeks, per the daughter, but today per the personal aide, became agitated and uncomfortable at about 2:30 p.m.  At about 7 p.m., the patient began vomiting, was noted to be short of breath by her daughter with garbled speech, arms flopping, and irregular head movements.  Her daughter called 911 and her symptoms seemed to improve.  Then, she began vomiting.  When the patient's daughter asked her if she had chest pain, the patient said yes.,She came to the emergency room, an EKG showed inferior ST-elevation MI.  I was called immediately and knowing her history, especially, her hospice status with recent hemorrhagic pericardial effusion, I felt thrombolytic was contraindicated and she would not be a candidate for aggressive interventional therapy with PCI/CABG.  She was begun after discussion with the oncologist, on heparin drip and has received morphine, nitro, and beta-blocker, and currently states that she is pain free.  Repeat EKG shows normalization of her ST elevation in the inferior leads as well as normalization of prior reciprocal changes.,PAST MEDICAL HISTORY: , Significant for metastatic non-small-cell lung cancer.  In early-to-mid December, she had an admission and was found to have a malignant pericardial effusion with tamponade requiring urgent drainage.  We did repeat an echo several weeks later and that did not show any recurrence of the pericardial effusion.  She is on hospice from the medical history, atrial fibrillation, hypertension, history of multiple CVA.,MEDICATIONS: , Medications as an outpatient:,1.  Amiodarone 200 mg once a day.,2.  Roxanol concentrate 5 mg three hours p.r.n. pain.,ALLERGIES:  ,CODEINE.  NO SHRIMP, SEAFOOD, OR DYE ALLERGY.,FAMILY HISTORY: , Negative for cardiac disease.,SOCIAL HISTORY: , She does not smoke cigarettes.  She uses alcohol.  No use of illicit drugs.  She is divorced and lives with her daughter.  She is a retired medical librarian from Florida.,REVIEW OF SYSTEMS:  ,Unable to be obtained due to the patient's aphasia.,PHYSICAL EXAMINATION: , Height 5 feet 3, weight of 106 pounds, temperature 97.1 degrees, blood pressure ranges from 138/82 to 111/87, pulse 61, respiratory rate 22.  O2 saturation 100%.  On general exam, she is an elderly woman with now marked aphasia, which per her daughter waxes and wanes, was more pronounced and she nods her head up and down when she says the word, no, and conversely, she nods her head side-to-side when she uses the word yes with some discordance in her head gestures with vocalization.  HEENT shows the cranium is normocephalic and atraumatic.  She has dry mucosal membrane.  She now has a right facial droop, which per her daughter is new.  Neck veins are not distended.  No carotid bruits visible.  Skin:  Warm, well perfused.  Lungs are clear to auscultation anteriorly.  No wheezes.  Cardiac exam:  S1, S2, regular rate.  No significant murmurs.  PMI is nondisplaced.  Abdomen:  Soft, nondistended.  Extremities:  Without edema, on limited exam.  Neurological exam seems to show only the right facial droop.,DIAGNOSTIC/LABORATORY DATA: , EKGs as reviewed above.  Her last ECG shows normalization of prior ST elevation in the inferior leads with Q waves and first-degree AV block, PR interval 280 milliseconds.  Further lab shows sodium 135, potassium 4.2, chloride 98, bicarbonate 26, BUN 9, creatinine 0.8, glucose 162, troponin 0.17, INR 1.27, white blood cell count 1.3, hematocrit 31, platelet count of 179.,Chest x-ray, no significant pericardial effusion.,IMPRESSION: , The patient is a 69-year-old woman with metastatic non-small-cell lung cancer with a recent hemorrhagic pericardial effusion, now admitted with cerebrovascular accident and transient inferior myocardial infarction, which appears to be canalized.  I will discuss this in detail with the patient and her daughter, and clearly, her situation is quite guarded with likely poor prognosis, which they are understanding of.,RECOMMENDATIONS:,1.  I think it is reasonable to continue heparin, but clearly she would be at risk for hemorrhagic pericardial effusion recurrence.,2.  Morphine is appropriate, especially for preload reduction and other comfort measures as appropriate.,3.  Would avoid other blood thinners including Plavix, Integrilin, and certainly, she is not a candidate for a thrombolytic with which the patient and her daughter are in agreement with after a long discussion.,Other management as per the medical service.  I have discussed the case with Dr. X of the hospitalist service who will be admitting the patient.\"},\n",
       "  {'role': 'assistant', 'content': 'Cardiovascular / Pulmonary'}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_format(df):\n",
    "\n",
    "    formatted_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        entry = {\"messages\": [{'role':'system', 'content':system_prompt},{'role':'user', 'content':row['report']},{'role':'assistant','content':row['medical_specialty']}]}\n",
    "        formatted_data.append(entry)\n",
    "    return formatted_data\n",
    "\n",
    "data = df_to_format(train)\n",
    "data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('dataset/fine_tuning_data.jsonl','w') as f:\n",
    "    for entry in data:\n",
    "        f.write(json.dumps(entry))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = df_to_format(validation_data)\n",
    "\n",
    "with open('dataset/fine_tuning_data_val.jsonl','w') as f:\n",
    "    for entry in val_data:\n",
    "        f.write(json.dumps(entry))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_l = df_to_format(test_data)\n",
    "\n",
    "with open('dataset/fine_tuning_data_test.jsonl','w') as f:\n",
    "    for entry in test_data_l:\n",
    "        f.write(json.dumps(entry))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI tokenization : tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : https://github.com/openai/tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9906, 3492]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"Hello word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15339, 3492]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"hello word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_token_from_string(string):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_token_from_string(\"Hello word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_length = train[\"report\"].apply(num_token_from_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     500.000000\n",
       "mean      647.320000\n",
       "std       426.409512\n",
       "min         4.000000\n",
       "25%       323.000000\n",
       "50%       552.500000\n",
       "75%       872.250000\n",
       "max      2484.000000\n",
       "Name: report, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports_length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your own custom models by fine-tuning our base models with your training data. Once you fine-tune a model, youâ€™ll be billed only for the tokens you use in requests to that model.\n",
    "Learn about fine-tuning\n",
    "Model\tTraining\tInput usage\tOutput usage\n",
    "- gpt-3.5-turbo\t$0.0080 / 1K tokens\t$0.0030 / 1K tokens\t$0.0060 / 1K tokens\n",
    "- davinci-002\t    $0.0060 / 1K tokens\t$0.0120 / 1K tokens\t$0.0120 / 1K tokens\n",
    "- babbage-002\t    $0.0004 / 1K tokens\t$0.0016 / 1K tokens\t$0.0016 / 1K tokens\n",
    "\n",
    "source : https://openai.com/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323660"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports_length.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_per_epoch = reports_length.sum() * 0.008 / 1000 # per 1k tokens\n",
    "price_per_epoch # 2.7$ per epoch\n",
    "\n",
    "price_all_epochs = 2.7 * 10\n",
    "price_all_epochs # 27 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Retrieve the API key from the environment variable\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"No OpenAI API key found in environment variables\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAI.api_key = openai_api_key\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_upload_response = client.files.create(file=open(\"dataset/fine_tuning_data.jsonl\",\"rb\"), purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-RrIEoBwlgwhmWA1UJJKFk65I', bytes=1486483, created_at=1708454317, filename='fine_tuning_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_upload_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_upload_response_validation = client.files.create(file=open(\"dataset/fine_tuning_data_val.jsonl\",\"rb\"), purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-qcMUUhoGYJ9eYBs2yrrRVj0M', bytes=10346, created_at=1708454395, filename='fine_tuning_data_val.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_upload_response_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-RrIEoBwlgwhmWA1UJJKFk65I'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_upload_response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fine_tuning_response = client.fine_tuning.jobs.create(\n",
    "  training_file=file_upload_response.id, \n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  hyperparameters={'n_epochs':1},\n",
    "  validation_file=file_upload_response_validation.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-raweLrXtS7LObzaiwWtzjU4K', created_at=1708454652, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=1, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-A9O4pnYpV0Nyy6nxlLnVmaCE', result_files=[], status='validating_files', trained_tokens=None, training_file='file-RrIEoBwlgwhmWA1UJJKFk65I', validation_file='file-qcMUUhoGYJ9eYBs2yrrRVj0M')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-raweLrXtS7LObzaiwWtzjU4K', created_at=1708454652, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=1, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-A9O4pnYpV0Nyy6nxlLnVmaCE', result_files=[], status='running', trained_tokens=None, training_file='file-RrIEoBwlgwhmWA1UJJKFk65I', validation_file='file-qcMUUhoGYJ9eYBs2yrrRVj0M')], object='list', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "print(client.fine_tuning.jobs.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-abc123\")\n",
    "\n",
    "# Cancel a job\n",
    "client.fine_tuning.jobs.cancel(\"ftjob-abc123\")\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-abc123\", limit=10)\n",
    "\n",
    "# Delete a fine-tuned model (must be an owner of the org the model was created in)\n",
    "client.models.delete(\"ft:gpt-3.5-turbo:acemeco:suffix:abc123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo:my-org:custom_suffix:id\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
